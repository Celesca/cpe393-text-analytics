{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnPDwj0Fzy0z"
      },
      "source": [
        "# **Text Classification**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell if you use Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kWDsGl6pd6zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrgaDLwR0Khs"
      },
      "source": [
        "Load and read in dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDB9EqEbnK8r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "df = pd.read_pickle('consumer_complaint_dataset.data', compression='gzip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRVohqkzpOos"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek6b2YRk0fgZ"
      },
      "source": [
        "## Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzAE2xempTun"
      },
      "outputs": [],
      "source": [
        "pd.crosstab(df.topic, columns=\"Count\").sort_values(by='Count', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz2xD29e0lhg"
      },
      "source": [
        "## Group Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLg7MkXXpi74"
      },
      "outputs": [],
      "source": [
        "df.loc[df['topic']=='Credit reporting', 'topic'] = 'Credit reporting, credit repair services, or other personal consumer reports'\n",
        "df.loc[df['topic']=='Credit card', 'topic'] = 'Credit card or prepaid card'\n",
        "df.loc[df['topic']=='Prepaid card', 'topic'] = 'Credit card or prepaid card'\n",
        "df.loc[df['topic']=='Payday load', 'topic'] = 'Payday loan, title loan, or personal loan'\n",
        "df.loc[df['topic']=='Virtual currency', 'topic'] = 'Money transfer, virtual currency, or money service'\n",
        "df.loc[df['topic']=='Money transfers', 'topic'] = 'Money transfer, virtual currency, or money service'\n",
        "df = df[df['topic'] != 'Other financial service']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PraryJR0qkj"
      },
      "source": [
        "## Labels after grouping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n28WzcMNrMz8"
      },
      "outputs": [],
      "source": [
        "pd.crosstab(df.topic, columns=\"Count\").sort_values(by='Count', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc-leOV0rTU4"
      },
      "outputs": [],
      "source": [
        "df['topic'].value_counts().sort_values(ascending=False).plot(kind='bar',title='Number of complaints per topic')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUSci0Ls0xvb"
      },
      "source": [
        "## Function to retrieve text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiSEgvd3rmWW"
      },
      "outputs": [],
      "source": [
        "def print_plot(index):\n",
        "  example = df[df.index == index][['input','topic']].values[0]\n",
        "  if len(example)>0:\n",
        "    print(example[0])\n",
        "    print('Topic: ',example[1])\n",
        "print_plot(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNw3z-Kk02Ci"
      },
      "source": [
        "## Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoBH0mubr-pa"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmQ0YoA0tTpf"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAQMVsucsNYE"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "REPLACE_BY_SPLACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1oxYw0-1HMo"
      },
      "source": [
        "## Function to clean text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "covdiCtmtZE5"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  text = REPLACE_BY_SPLACE_RE.sub(' ', text)\n",
        "  text = BAD_SYMBOLS_RE.sub('', text)\n",
        "  text = text.replace('x', '')\n",
        "  text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JN7IIlJ2txgN"
      },
      "outputs": [],
      "source": [
        "df['input'] = df['input'].apply(clean_text)\n",
        "\n",
        "df['input'] = df['input'].str.replace('\\d+','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xXVNPcVvF1G"
      },
      "outputs": [],
      "source": [
        "print_plot(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGajc2A1vJ1-"
      },
      "source": [
        "# Modeling\n",
        "1. Vectorize input consumer complaints\n",
        "2. Limit dataset to top 50000 words\n",
        "3. Set max number of words in each complaint to 250"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3EyM7Un1ZE0"
      },
      "source": [
        "## Train Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGO5S1iFvn_g"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "MAX_NB_WORDS = 50000\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 250\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words = MAX_NB_WORDS,\n",
        "                      filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',\n",
        "                      lower=True)\n",
        "tokenizer.fit_on_texts(df['input'].values)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.'%len(word_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQSrJna4yQVJ"
      },
      "source": [
        "## Pad sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAKIL1sQyS4f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df['input'].values)[:2500]\n",
        "X = pad_sequences(X, maxlen = MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ7I4XzezRlX"
      },
      "outputs": [],
      "source": [
        "df['input'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip-bDRn7zWyV"
      },
      "outputs": [],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTnSWCKDzaId"
      },
      "source": [
        "## Convert output label into numeric format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhkUr9v-zdOh"
      },
      "outputs": [],
      "source": [
        "Y = pd.get_dummies(df['topic']).values[:2500]\n",
        "print('Shape of label tensor:', Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3GAtS0yzpRW"
      },
      "outputs": [],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNlqj8BxzryJ"
      },
      "source": [
        "## Split dataset to Training and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSTiohaYzrdW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_test.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgh16tbv0Vbr"
      },
      "source": [
        "## Construct LSTM Text Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcgzW0ry0b0o"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(12, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epochs=3\n",
        "batch_size=64\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmSTOCU-KQYo"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d7WLcCTKXhQ"
      },
      "outputs": [],
      "source": [
        "acc = model.evaluate(X_test, Y_test)\n",
        "print('Test set \\n\\tLoss: {:0.3f}\\n\\tAccuracy: {:0.3f}'.format(acc[0], acc[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WGc4YD5MTer"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4cdgsSFMVOR"
      },
      "outputs": [],
      "source": [
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='Train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQQnVBbKxwMY"
      },
      "source": [
        "## Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfZezRXfxul0"
      },
      "outputs": [],
      "source": [
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='Train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "LkpofSWQf5XL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.get_dummies(df['topic']).columns\n",
        "list(labels)"
      ],
      "metadata": {
        "id": "M3YzxhbEf7TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# confusion_matrix(Y_test.argmax(axis=1),\n",
        "#                  y_pred.argmax(axis=1))\n",
        "\n",
        "pd.DataFrame(confusion_matrix(Y_test.argmax(axis=1),\n",
        "                              y_pred.argmax(axis=1)),\n",
        "             index=labels, columns=labels)"
      ],
      "metadata": {
        "id": "uzkOjq9tf9Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZP84YwzyNaV"
      },
      "source": [
        "## Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNaCT3XJyP7X"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_true=Y_test.argmax(axis=1),\n",
        "                            y_pred=y_pred.argmax(axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG0XCNc0y9bS"
      },
      "source": [
        "## Test using new complaints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOBUGnb1zWck"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "new_complaint = ['I am a victim of identity theft']\n",
        "seq = tokenizer.texts_to_sequences(new_complaint)\n",
        "padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "pred = model.predict(padded)\n",
        "labels=pd.get_dummies(df['topic']).columns.values\n",
        "print(pred, labels[np.argmax(pred)])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}